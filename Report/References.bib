@inproceedings{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  booktitle={Advances in neural information processing systems},
  pages={8571--8580},
  year={2018}
}

@article{yang2019scaling,
	title={Scaling limits of wide neural networks with weight sharing: Gaussian process behavior, gradient independence, and neural tangent kernel derivation},
	author={Yang, Greg},
	journal={arXiv preprint arXiv:1902.04760},
	year={2019}
}

@article{arora2019exact,
	title={On exact computation with an infinitely wide neural net},
	author={Arora, Sanjeev and Du, Simon S and Hu, Wei and Li, Zhiyuan and Salakhutdinov, Ruslan and Wang, Ruosong},
	journal={arXiv preprint arXiv:1904.11955},
	year={2019}
}

@article{yang2019tensor,
  title={Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any Architecture are Gaussian Processes},
  author={Yang, Greg},
  journal={arXiv preprint arXiv:1910.12478},
  year={2019}
}

@book{neal2012bayesian,
	title={Bayesian learning for neural networks},
	author={Neal, Radford M},
	volume={118},
	year={2012},
	publisher={Springer Science \& Business Media}
}

@inproceedings{glorot2010understanding,
	title={Understanding the difficulty of training deep feedforward neural networks},
	author={Glorot, Xavier and Bengio, Yoshua},
	booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
	pages={249--256},
	year={2010}
}